## BEGIN ANALYSIS: QUALITY CONTROL & FILTERING ##

## Metagenome sample key:
B1 = squaxin 
B2 = 2019a 
B3 = 2019b 
B4 = 2017a 
B5 = 2017b 
B6 = 2018a
B7 = 2018b 

## Start anvio

module load Anaconda3/2019.03
conda activate anvio-6.1

## Step 1: Quality Control
## Within anvio, use iu-gen-configs program with samples.txt to create config files for illumina-utils
## This tells the program where the input files are, as well as where the output should go
## Make output directory (01_QC)

iu-gen-configs 2019a.txt -o 01_QC

## Where the tile 2019a.txt contains your metagenome raw sample files, like this:
sample	r1	                     r2
B4	    B4_S4_L002_R1_001.fastq	 B4_S4_L002_R2_001.fastq

## The above code created the file “B2.ini” (~ 5 mins run time).
## Repeat iu-gen-configs for each of your metagenome samples!
## Now you are ready to run quality filtering for each of your samples with the following code:

iu-filter-quality-minoche 01_QC/B1.ini 

### Example results for metagenome sample B1: cat B1-STATS.txt

number of pairs analyzed      : 21,877,993
total pairs passed            : 20,141,653 (%92.06 of all pairs)
  total pair_1 trimmed        : 0 (%0.00 of all passed pairs)
  total pair_2 trimmed        : 0 (%0.00 of all passed pairs)
total pairs failed            : 1736340 (%7.94 of all pairs)
  pairs failed due to pair_1  : 306997 (%17.68 of all failed pairs)
  pairs failed due to pair_2  : 928052 (%53.45 of all failed pairs)
  pairs failed due to both    : 501291 (%28.87 of all failed pairs)

##############################################################

## Step 2: Assemble short reads into contigs with IDBA-UD (Peng et al. 2012)

## ADD ASSEMBLY DETAILS FROM EMILY
anvio snakemake pipeline (see Emily_MAG_assembly_snakemake_pipeline.txt)

Final co-assembly
g1 = B1 (Squaxin)
g2 = B2 (2019a) + B3 (2019b)
g3 = B4 (2017a) + B5 (2017b)
g4 = B6 (2018a) + B7 (2018b)

## How to display the stats for the contigs:
cd 03_CONTIGS

anvi-display-contigs-stats g1-contigs.db

contigs.fasta are the assembled contigs
BAM files = files with short reads mapped to contigs

## Create a new anvio profile for each sample assembly:

Creates a single anvi'o profile database. The default input to this program is
a BAM file. When it is run on a BAM file, depending on the user parameters,
the program quantifies coverage per nucleotide position (and averages them out
per contig), calculates single-nucleotide, single-codon, and single-amino acid
variants, and stores these data into appropriate tables. 

## Start anvio

module load Anaconda3/2019.03
conda activate anvio-6.1

## Example code for creating an anvio profile database for a single metagenome sample
anvi-profile -i 04_MAPPING/g1/B1.bam -c 03_CONTIGS/g1-contigs.db --min-contig-length 2500 -o 05_NEW_ANVIO_PROFILES/Squaxin --sample-name Squaxin

## Note: I didn’t use “anti-cluster-contigs” for the single samples (will do this for the merged database), so anvi-interactive can’t display anything right now
## Note: This step takes a lot of time - from 2 to 15 hours per profile, run on a server with a batch script

## If you have any co-assembled samples, merge your profile databases:
## Merge databases: 2019 = B2 (2019a) + B3 (2019b)
anvi-merge 05_NEW_ANVIO_PROFILES/B2/PROFILE.db 05_NEW_ANVIO_PROFILES/B3/PROFILE.db --enforce-hierarchical-clustering -c 03_CONTIGS/g2-contigs.db -o 06_NEW_MERGED/2019 -S y2019

## This step was fast, from 2-15 minutes

## Next step: Importing taxonomy calls for genes using scg-taxonomy

## Example:
anvi-run-scg-taxonomy -c 03_CONTIGS/g1-contigs.db --num-parallel-processes 3 --num-threads 2

## Estimate the genomes and taxonomy of bacteria in your metagenome sample (not final taxonomy & you haven't assembled any genomes yet, just a rough estimate)
anvi-estimate-genome-taxonomy -c 03_CONTIGS/g1-contigs.db -p 05_NEW_ANVIO_PROFILES/B1/PROFILE.db --metagenome-mode --compute-scg-coverages --update-profile-db-with-taxonomy

##################################################

## Next step: Map short reads from all metagenome samples to all contig assemblies (aka recruitment of metagenomic reads)

## load your modules here
module load Anaconda3/2019.03
conda activate anvio-6.1

## Example: mapping samples to g1 assembly in Bowtie2

## Mapping sample B1 to assembly g1... repeat for all samples (B1-B7)
## STEP_1
bowtie2 --threads 4 -x 04_MAPPING/g1/g1-contigs -1 01_QC/B1-QUALITY_PASSED_R1.fastq -2 01_QC/B1-QUALITY_PASSED_R2.fastq -S 04_MAPPING/g1/B1.sam
## STEP_2
samtools view -F 4 -bS 04_MAPPING/g1/B1.sam > 04_MAPPING/g1/B1-RAW.bam
## STEP_3
anvi-init-bam 04_MAPPING/g1/B1-RAW.bam -o 04_MAPPING/g1/B1.bam
## STEP_4
rm 04_MAPPING/g1/B1.sam 04_MAPPING/g1/B1-RAW.bam

... repeat above steps for all of your samples, mapping them to each contig assembly using Bowtie2 in anvio

##############################################

Profiling the mapping results with anvi’o:
## Re-profile databases to contain the mapped reads from all 7 metagenome samples:
## Now that I have all of the sample reads mapped to each of the 4 contigs databases, I need to reprofile
## Each single .BAM file to each of the 4 contigs databases, so 7 samples x 4 contigs.db = 28 profiles!

## This is an example for one of my contigs databases (g1-contigs.db), where I profiled each of the 7 BAM files (B1.bam through B7.bam) against each contigs database
# Note: don't use the flag --cluster-contigs because I will merge multiple profiles at the end!
anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B1.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B1 --sample-name B1

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B2.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B2 --sample-name B2

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B3.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B3 --sample-name B3

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B4.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B4 --sample-name B4

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B5.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B5 --sample-name B5

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B6.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B6 --sample-name B6

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B7.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B7 --sample-name B7

##############################################

Generating merged anvi’o profiles:
## Next, merge profiles together for each contigs database. Merge the 7 profiles for each single contigs database into a single, merged database
## The asterisk (*) selects any character, so in this case, any character that directly follows a B, selecting B1, B2, B3, B4... to B7.

anvi-merge /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B*/PROFILE.db --enforce-hierarchical-clustering -o 06_NEW_MERGED/g1
-S squaxin -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db

##############################################

## Next step: Binning contigs into MAGS (metagenome-assembled-genomes) using anvi-interactive

## Tips for using anvi-interactive while working on a remote server:

## First, look up your computer’s IP address (it will print the # in your terminal):
/sbin/ip route get 8.8.8.8 | awk '{print $NF;exit}'
## it will print something like this: 128.135.112.69

## Now, use anvi-interactive, but you need to include your computer’s IP address with the -I option. For example:
anvi-interactive -p 06_NEW_MERGED/2018/PROFILE.db -c 03_CONTIGS/g4-contigs.db -I 128.135.112.69

## Then go to a browser and type: http://your_IP_address:8080/

Example: http://10.50.221.6:8080/

####################################

## Binning contigs into MAGS (metagenome-assembled-genomes) using anvi-interactive

## First check: estimate how many genomes are in each co-assembled sample with display contigs stats!
## This will give you a very rough & approximate number of bacterial & archaeal genomes to expect in your contig assemblies, based on single copy core genes
anvi-display-contigs-stats 03_CONTIGS/g1-contigs.db -I 128.135.112.69

## To cluster contigs into MAGs, manual binning and refinement was performed using “anvi-interactive” with both sequence composition (tetranucleotide frequency) 
and differential coverage across all samples, following previously described approaches to generate high quality MAGs (Delmont et al. 2018, Shaiber et al. 2020)

## For resources on manual binning, please see:
https://merenlab.org/tutorials/infant-gut/#manual-identification-of-genomes-in-the-infant-gut-dataset
https://merenlab.org/data/tara-oceans-mags/
https://merenlab.org/2017/01/03/loki-the-link-archaea-eukaryota/ (good video tutorials)

## For more information on bin completion & redundancy, please see:
https://merenlab.org/2016/06/09/assessing-completion-and-contamination-of-MAGs/

## To begin binning, run anvi-interactive in "contigs" mode:
## Note: only use -I if you are working on a remote server and sending the output to your computer

anvi-interactive -p 05_NEW_ANVIO_PROFILES/B1/PROFILE.db -c 03_CONTIGS/g1-contigs.db -I 128.135.112.69

^ This will display a hierarchical clustering of all contigs in a given database, with concentric circles showing GC content and coverage across your metagenome samples

## Tips:
- In the general / layers tab of anvi-interactice, click view: sequence composition + differential coverage to bin samples according to both sequence composition & differential coverage across samples
- Always start with large, coarse bins that have high redundancy, and slowly split & refine your bins into smaller bins until they have low redundauncy using anvi-refine
- You don't need to bin ALL contigs - some will be left "unbinned" and that is okay
- Bins should have HIGH completion (>70%) and LOW redundancy (<10%) - redundancy is also called contamination. See resource listred above
- Completion almost never gets to 100%
- If you mess up, right click “remove item from bin”
- Differential coverage across samples is KEY and will help you discriminate between MAGS with similar GC content
- For differential coverage, follow read mapping instructions above to map short reads to each contig assembly
- Don’t sacrifice bin completion for getting a slightly lower redundancy value – leads to wasting too much genomic information that could be useful
- If you are stuck with a bin, try viewing by either sequence composition (GC content) or differential coverage alone – it might help make it clear which contigs should or shouldn’t be part of that bin
- As you refine your bin collection, save it as a new collection (such as manual_bins_refined) in case you want to go back and look at your unrefined bins later!
- Double-check all of the bins at the end – go into each one using anvi-refine and manually inspect it!
- As above, I will emphasize that it is good to double-check everything before moving on to further downstream analyses

## Once you begin binning, store your bin collection & give it a name. Every time you run anvi-interactive, you can load this bin collection & continue binning from where you left off

## After you create coarse bins, use “anvi-refine” to inspect each bin individually for contaminating contig clusters with dissimilar GC content and differential coverage
## Using anvi-refine usually leads to splitting bins into multiple bins with lower redundancy
## Use ani-refine as follows, with the -b flag for each bin in your collection (-C indicates the bin collection name): 

anvi-refine -p 06_NEW_MERGED/g1/PROFILE.db -c 03_CONTIGS/g1-contigs.db -C Manual_bins_unrefined -b Bin_1 -I 128.135.112.69

####################################

Summarize the binning results

## Once you are satisfied with your bin collection, or if you want to stop and check the stats on your bins, use the following command to summarize your bins:
anvi-summarize -p 06_NEW_MERGED/g2/PROFILE.db -c 03_CONTIGS/g2-contigs.db -C Manual_bins_refined -o 06_NEW_MERGED/g2/Manual_bins_refined_summary

## Once you are done refining your bin collection, you can rename them and save as a collection of MAGs (metagenome assembled genomes) using this command:

anvi-rename-bins -c 03_CONTIGS/g2-contigs.db -p 06_NEW_MERGED/g2/PROFILE.db --collection-to-read Manual_bins_refined --collection-to-write MAGs
--min-completion-for-MAG 50 --max-redundancy-for-MAG 10 --call-MAG --report-file 06_NEW_MERGED/g2/MAGs --prefix g2

## Using the --min-completion and --max-redundancy flags will remove bins with less than 50% completion and/or greater than 10% redundancy
## Other bins (with less than 50% completion and/or greater than 10% redundancy) are still left but are renamed as “bins” and not “MAGs”
## Delete the low quality bins and save a new collection called “MAGs_final” which only has the final MAGs (not bins)

## Create a summary of your final MAG collection:
anvi-summarize -p 06_NEW_MERGED/g3/PROFILE.db -c 03_CONTIGS/g3-contigs.db -C Manual_bins_refined -o 06_NEW_MERGED/g3/Manual_bins_refined_summary
