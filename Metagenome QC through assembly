## Begin analysis: quality control of metagenomic reads

Step 1: Quality Control
## Within anvio, use iu-gen-configs program with samples.txt to create config files for illumina-utils
## This tells the program where the input files are, as well as where the output should go
## Make output directory (01_QC)

iu-gen-configs 2019a.txt -o 01_QC

## Where the tile 2019a.txt contains your metagenome raw sample files, like this:
sample	r1	                     r2
B4	    B4_S4_L002_R1_001.fastq	 B4_S4_L002_R2_001.fastq

## The above code created the file “B2.ini” (~ 5 mins run time).
## Repeat iu-gen-configs for each of your metagenome samples!

# Raw sequences from forward and reverse reads were checked for sequence quality using “filter-quality-minoche” (Minoche et al. 2011)
# Within anvio, we used the following code:

iu-filter-quality-minoche 01_QC/B1.ini 

### Example results for metagenome sample B1: cat B1-STATS.txt

number of pairs analyzed      : 21,877,993
total pairs passed            : 20,141,653 (%92.06 of all pairs)
  total pair_1 trimmed        : 0 (%0.00 of all passed pairs)
  total pair_2 trimmed        : 0 (%0.00 of all passed pairs)
total pairs failed            : 1736340 (%7.94 of all pairs)
  pairs failed due to pair_1  : 306997 (%17.68 of all failed pairs)
  pairs failed due to pair_2  : 928052 (%53.45 of all failed pairs)
  pairs failed due to both    : 501291 (%28.87 of all failed pairs)

##############################################################

Step 2: Quality sequences were assembled into contigs using IDBA-UD (Peng et al. 2012) with a minimum contig length of 1,000.

## Metagenomes collected from the same kelp forest location and same year were co-assembled, resulting in 4 total assemblies.
## We did not assemble across multiple years or locations to avoid chimeric genomes. 

## Names of the 4 metagenome assemblies according to sampling location and year:
g1 = B1 (Squaxin)
g2 = B2 (2019a) + B3 (2019b)
g3 = B4 (2017a) + B5 (2017b)
g4 = B6 (2018a) + B7 (2018b)

## Metagenomes were assembled into contigs using a snakemake pipeline in anvio, with the following settings for IDBA:
 "idba_ud": {
        "--min_contig": 1000,
        "threads": 35,
        "run": true,
        "--mink": "",
        "--maxk": "",
        "--step": "",
        "--inner_mink": "",
        "--inner_step": "",
        "--prefix": "",
        "--min_count": "",
        "--min_support": "",
        "--seed_kmer": "",
        "--similar": "",
        "--max_mismatch": "",
        "--min_pairs": "",
        "--no_bubble": "",
        "--no_local": "",
        "--no_coverage": "",
        "--no_correct": "",
        "--pre_correction": "",
        "use_scaffolds": ""}
        
## The command “anvi-gen-contigs-database” was used to generate contigs databases, which computes k-mer frequencies and identifies open reading frames with Prodigal (Hyatt et al. 2010). 

anvi-gen-contigs-database -f assembled_metagenome_g1.fa -o g1-CONTIGS.db
anvi-gen-contigs-database -f assembled_metagenome_g2.fa -o g2-CONTIGS.db
anvi-gen-contigs-database -f assembled_metagenome_g3.fa -o g3-CONTIGS.db
anvi-gen-contigs-database -f assembled_metagenome_g4.fa -o g4-CONTIGS.db

## After assembly, display the stats for the assembled contigs:

anvi-display-contigs-stats g1-contigs.db
anvi-display-contigs-stats g2-contigs.db
anvi-display-contigs-stats g3-contigs.db
anvi-display-contigs-stats g4-contigs.db

##############################################################

Step 3: Create a new anvio profile for each sample assembly:

From anvio about the code "anvi-profile": Creates a single anvi'o profile database. The default input to this program is a BAM file.
When it is run on a BAM file, depending on the user parameters, the program quantifies coverage per nucleotide position (and averages them out per contig),
calculates single-nucleotide, single-codon, and single-amino acid variants, and stores these data into appropriate tables."

## Example code for creating an anvio profile database for a single metagenome sample
anvi-profile -i 04_MAPPING/g1/B1.bam -c 03_CONTIGS/g1-contigs.db --min-contig-length 2500 -o 05_NEW_ANVIO_PROFILES/Squaxin --sample-name Squaxin

## Note: I didn’t use “anti-cluster-contigs” for the single samples (will do this for the merged database), so anvi-interactive can’t display anything right now
## Note: This step takes a lot of time - from 2 to 15 hours per profile, run on a server with a batch script

## If you have any co-assembled samples, merge your profile databases:
## Merge databases: 2019 = B2 (2019a) + B3 (2019b)
anvi-merge 05_NEW_ANVIO_PROFILES/B2/PROFILE.db 05_NEW_ANVIO_PROFILES/B3/PROFILE.db --enforce-hierarchical-clustering -c 03_CONTIGS/g2-contigs.db -o 06_NEW_MERGED/2019 -S y2019

## Next step: Importing taxonomy calls for genes using scg-taxonomy

## Example:
anvi-run-scg-taxonomy -c 03_CONTIGS/g1-contigs.db --num-parallel-processes 3 --num-threads 2

## Estimate the genomes and taxonomy of bacteria in your metagenome sample (not final taxonomy & you haven't assembled any genomes yet, just a rough estimate)
anvi-estimate-genome-taxonomy -c 03_CONTIGS/g1-contigs.db -p 05_NEW_ANVIO_PROFILES/B1/PROFILE.db --metagenome-mode --compute-scg-coverages --update-profile-db-with-taxonomy

##############################################################

Step 4: Map short reads from all metagenome samples to all contig assemblies (aka recruitment of metagenomic short reads)

## Example: Mapping metagenome reads to g1 assembly in Bowtie2

## Mapping sample B1 to assembly g1... repeat for all samples (B1-B7)
## STEP_1
bowtie2 --threads 4 -x 04_MAPPING/g1/g1-contigs -1 01_QC/B1-QUALITY_PASSED_R1.fastq -2 01_QC/B1-QUALITY_PASSED_R2.fastq -S 04_MAPPING/g1/B1.sam
## STEP_2
samtools view -F 4 -bS 04_MAPPING/g1/B1.sam > 04_MAPPING/g1/B1-RAW.bam
## STEP_3
anvi-init-bam 04_MAPPING/g1/B1-RAW.bam -o 04_MAPPING/g1/B1.bam
## STEP_4
rm 04_MAPPING/g1/B1.sam 04_MAPPING/g1/B1-RAW.bam

... repeat above steps for all of your samples, mapping them to each contig assembly using Bowtie2 in anvio

##############################################################

Step 5: Profile the mapping results with anvi’o:
## To perform metagenomic binning of contigs using anvio, profile databases were generated from BAM files and contigs databases using “anvi-profile”
with a minimum contig length of 2,500 (to visualize all contigs)
## Re-profile databases to contain the mapped reads from all 7 metagenome samples:
## With sample reads mapped to each of the 4 contigs databases, reprofile each single .BAM file to each of the 4 contigs databases, so 7 samples x 4 contigs.db = 28 profiles!

## This is an example for one of my contigs databases (g1-contigs.db), where I profiled each of the 7 BAM files (B1.bam through B7.bam) against each contigs database
# Note: don't use the flag --cluster-contigs because I will merge multiple profiles at the end!
anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B1.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B1 --sample-name B1

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B2.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B2 --sample-name B2

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B3.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B3 --sample-name B3

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B4.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B4 --sample-name B4

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B5.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B5 --sample-name B5

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B6.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B6 --sample-name B6

anvi-profile -i /project2/cpfister/nereoblade/emily_assemblies/04_MAPPING/g1/B7.bam -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db
--min-contig-length 2500 -o /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B7 --sample-name B7

##############################################################

Step 6: Generating merged anvi’o profiles:
## To perform metagenomic binning of contigs using anvio, profiles for co-assembled samples were merged. 
## The asterisk (*) selects any character, so in this case, any character that directly follows a B, selecting B1, B2, B3, B4... to B7.

anvi-merge /project2/cpfister/nereoblade/emily_assemblies/05_NEW_ANVIO_PROFILES/g1/B*/PROFILE.db --enforce-hierarchical-clustering -o 06_NEW_MERGED/g1
-S squaxin -c /project2/cpfister/nereoblade/emily_assemblies/03_CONTIGS/g1-contigs.db

##############################################################

Step 7: Binning contigs into MAGS (metagenome-assembled-genomes) - tips for using anvi-interactive on a remote server

## Tips for using anvi-interactive while working on a remote server:
## First, look up your computer’s IP address (it will print the # in your terminal):
/sbin/ip route get 8.8.8.8 | awk '{print $NF;exit}'
## it will print something like this: 121.145.122.69

## Now, use anvi-interactive, but you need to include your computer’s IP address with the -I option. For example:
anvi-interactive -p 06_NEW_MERGED/2018/PROFILE.db -c 03_CONTIGS/g4-contigs.db -I 121.145.122.69

## Then go to a browser and type: http://your_IP_address:8080/

Example: http://121.145.122.69:8080/

##############################################################

Step 7: Binning contigs into MAGS (metagenome-assembled-genomes) manually using anvi-interactive

## First check: estimate how many genomes are in each co-assembled sample with display contigs stats!
## This will give you a very rough & approximate number of bacterial & archaeal genomes to expect in your contig assemblies, based on single copy core genes
anvi-display-contigs-stats 03_CONTIGS/g1-contigs.db -I your_IP_address

## While binning, microbial taxonomy was estimated within anvio using “anvi-run-scg-taxonomy,” which searches single-copy genes from each genome against the Genome Taxonomy Database (GTDB):
anvi-run-scg-taxonomy -c CONTIGS.db --num-threads 5

## To cluster (or "bin") contigs into MAGs, manual binning and refinement was performed using “anvi-interactive” with both sequence composition (tetranucleotide frequency) 
and differential coverage across all samples, following previously described approaches to generate high quality MAGs (Delmont et al. 2018, Shaiber et al. 2020)

## For resources on manual binning, please see:
https://merenlab.org/tutorials/infant-gut/#manual-identification-of-genomes-in-the-infant-gut-dataset
https://merenlab.org/data/tara-oceans-mags/
https://merenlab.org/2017/01/03/loki-the-link-archaea-eukaryota/ (good video tutorials)

## For more information on bin completion & redundancy, please see:
https://merenlab.org/2016/06/09/assessing-completion-and-contamination-of-MAGs/

## To begin binning, run anvi-interactive in "contigs" mode:
## Note: only use -I if you are working on a remote server and sending the output to your computer

anvi-interactive -p 05_NEW_ANVIO_PROFILES/B1/PROFILE.db -c 03_CONTIGS/g1-contigs.db -I your_IP_address

^ This will display a hierarchical clustering of all contigs in a given database, with concentric circles showing GC content and coverage across your metagenome samples

## Tips:
- In the general / layers tab of anvi-interactice, click view: sequence composition + differential coverage to bin samples according to both sequence composition & differential coverage across samples
- Always start with large, coarse bins that have high redundancy, and slowly split & refine your bins into smaller bins until they have low redundauncy using anvi-refine
- You don't need to bin ALL contigs - some will be left "unbinned" and that is okay
- Bins should have HIGH completion (>70%) and LOW redundancy (<10%) - redundancy is also called contamination. See resource listred above
- Completion almost never gets to 100%
- If you mess up, right click “remove item from bin”
- Differential coverage across samples is KEY and will help you discriminate between MAGS with similar GC content
- For differential coverage, follow read mapping instructions above to map short reads to each contig assembly
- Don’t sacrifice bin completion for getting a slightly lower redundancy value – leads to wasting too much genomic information that could be useful
- If you are stuck with a bin, try viewing by either sequence composition (GC content) or differential coverage alone – it might help make it clear which contigs should or shouldn’t be part of that bin
- As you refine your bin collection, save it as a new collection (such as manual_bins_refined) in case you want to go back and look at your unrefined bins later!
- Double-check all of the bins at the end – go into each one using anvi-refine and manually inspect it!a

## Once you begin binning, store your bin collection & give it a name. Every time you run anvi-interactive, you can load this bin collection & continue binning from where you left off

## After you create coarse bins, use “anvi-refine” to inspect each bin individually for contaminating contig clusters with dissimilar GC content and differential coverage
## Using anvi-refine usually leads to splitting bins into multiple bins with lower redundancy
## Use ani-refine as follows, with the -b flag for each bin in your collection (-C indicates the bin collection name): 

anvi-refine -p 06_NEW_MERGED/g1/PROFILE.db -c 03_CONTIGS/g1-contigs.db -C Manual_bins_unrefined -b Bin_1 -I your_IP_address

##############################################################

Step 8: Summarize the binning results

## Once you are satisfied with your bin collection, or if you want to stop and check the stats on your bins, use the following command to summarize your bins:
anvi-summarize -p 06_NEW_MERGED/g2/PROFILE.db -c 03_CONTIGS/g2-contigs.db -C Manual_bins_refined -o 06_NEW_MERGED/g2/Manual_bins_refined_summary

## Once you are done refining your bin collection, you can rename them and save as a collection of MAGs (metagenome assembled genomes) using this command:

anvi-rename-bins -c 03_CONTIGS/g2-contigs.db -p 06_NEW_MERGED/g2/PROFILE.db --collection-to-read Manual_bins_refined --collection-to-write MAGs
--min-completion-for-MAG 50 --max-redundancy-for-MAG 10 --call-MAG --report-file 06_NEW_MERGED/g2/MAGs --prefix g2

## Using the --min-completion and --max-redundancy flags will remove bins with less than 50% completion and/or greater than 10% redundancy
## Other bins (with less than 50% completion and/or greater than 10% redundancy) are still left but are renamed as “bins” and not “MAGs”
## Delete the low quality bins and save a new collection called “MAGs_final” which only has the final MAGs (not bins)

## Create a summary of your final MAG collection:
anvi-summarize -p 06_NEW_MERGED/g3/PROFILE.db -c 03_CONTIGS/g3-contigs.db -C Manual_bins_refined -o 06_NEW_MERGED/g3/Manual_bins_refined_summary

##############################################################

## Now you have quality checked your metagenomic reads, assembled them into contigs, and binned those contigs into MAGs (metagenome-assembled-genomes).
## The next code file details what happens next (analysis and visualization of MAGs)

